{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mnist.ipynb","provenance":[],"authorship_tag":"ABX9TyPCpizNWP13MX8BWYhOxmD4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xDMkiAn7Y0gT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"1143c096-0711-4c83-852d-280b52c3c800","executionInfo":{"status":"ok","timestamp":1588587264914,"user_tz":-180,"elapsed":1319,"user":{"displayName":"Алёна Пахомова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL8YpyjVaEwzWTAkVURE1l8BR9-u0jeGeoDJzS=s64","userId":"04877045198898156253"}}},"source":["%pylab inline\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.utils.data.dataloader as dataloader\n","import torch.optim as optim\n","\n","from torch.utils.data import TensorDataset\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","\n","SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Populating the interactive namespace from numpy and matplotlib\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['test']\n","`%matplotlib` prevents importing * from pylab and numpy\n","  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZnAfrknyp_vu","colab_type":"code","colab":{}},"source":["train = MNIST('./data', train=True, download=True, transform=transforms.Compose([\n","    transforms.ToTensor(), # ToTensor does min-max normalization. \n","]), )\n","\n","test = MNIST('./data', train=False, download=True, transform=transforms.Compose([\n","    transforms.ToTensor(), # ToTensor does min-max normalization. \n","]), )\n","\n","# Create DataLoader\n","dataloader_args = dict(shuffle=True, batch_size=256,num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","train_loader = dataloader.DataLoader(train, **dataloader_args)\n","test_loader = dataloader.DataLoader(test, **dataloader_args)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTKqzjPwqG0k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":401},"outputId":"703cfb00-e009-4125-88c4-5f300b84a7ff","executionInfo":{"status":"error","timestamp":1588587471746,"user_tz":-180,"elapsed":4283,"user":{"displayName":"Алёна Пахомова","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL8YpyjVaEwzWTAkVURE1l8BR9-u0jeGeoDJzS=s64","userId":"04877045198898156253"}}},"source":["import gzip\n","train_data = train.train_data\n","train_data = train.transform(train_data.numpy())\n","\n","print('[Train]')\n","print(' - Numpy Shape:', train.train_data.cpu().numpy().shape)\n","print(' - Tensor Shape:', train.train_data.size())\n","print(' - min:', torch.min(train_data))\n","print(' - max:', torch.max(train_data))\n","print(' - mean:', torch.mean(train_data))\n","print(' - std:', torch.std(train_data))\n","print(' - var:', torch.var(train_data))\n","\n","mndata = train_data\n","mndata.gz = True\n","imagesTrain, labelsTrain = mndata.load_training()\n","imagesTest, labelsTest = mndata.load_testing()\n","x_train = np.asarray(imagesTrain)\n","y_train = np.asarray(labelsTrain)\n","x_test = np.asarray(imagesTest)\n","y_test = np.asarray(labelsTest)\n","img_rows, img_cols = 28, 28\n","# Выводим 4 первые изображения тестового набора\n","plt.subplot(2,2,1)\n","plt.imshow(x_test[0].reshape(img_rows, img_cols), cmap=plt.get_cmap('gray'))\n","plt.subplot(2,2,2)\n","plt.imshow(x_test[1].reshape(img_rows, img_cols), cmap=plt.get_cmap('gray'))\n","plt.subplot(2,2,3)\n","plt.imshow(x_test[2].reshape(img_rows, img_cols), cmap=plt.get_cmap('gray'))\n","plt.subplot(2,2,4)\n","plt.imshow(x_test[3].reshape(img_rows, img_cols), cmap=plt.get_cmap('gray'))\n","plt.show()"],"execution_count":89,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n","  warnings.warn(\"train_data has been renamed data\")\n"],"name":"stderr"},{"output_type":"stream","text":["[Train]\n"," - Numpy Shape: (60000, 28, 28)\n"," - Tensor Shape: torch.Size([60000, 28, 28])\n"," - min: tensor(0.)\n"," - max: tensor(1.)\n"," - mean: tensor(0.1305)\n"," - std: tensor(0.3081)\n"," - var: tensor(0.0949)\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-89-40a527db6b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmndata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mimagesTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mimagesTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelsTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmndata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagesTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'load_training'"]}]},{"cell_type":"code","metadata":{"id":"69AK5m-HT8Af","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bmGfxQ2qThN","colab_type":"code","colab":{}},"source":["# One hidden Layer NN\n","class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.fc = nn.Linear(784, 1000)\n","        self.fc2 = nn.Linear(1000, 10)\n","\n","    def forward(self, x):\n","        x = x.view((-1, 784))\n","        h = F.relu(self.fc(x))\n","        h = self.fc2(h)\n","        return F.log_softmax(h)    \n","    \n","    \n","model = Model()\n","if cuda:\n","    model.cuda() # CUDA!\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zGB_w1q7qXVk","colab_type":"code","colab":{}},"source":["EPOCHS = 5\n","losses = []\n","\n","model.train()\n","for epoch in range(EPOCHS):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Get Samples\n","        data, target = Variable(data), Variable(target)\n","        \n","        if cuda:\n","            data, target = data.cuda(), target.cuda()\n","        \n","        # Init\n","        optimizer.zero_grad()\n","\n","        # Predict\n","        y_pred = model(data) \n","\n","        # Calculate loss\n","        loss = F.cross_entropy(y_pred, target)\n","        losses.append(loss.cpu().data)\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        \n","        \n","        # Display\n","        if batch_idx % 100 == 1:\n","            print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch+1,\n","                EPOCHS,\n","                batch_idx * len(data), \n","                len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), \n","                loss.cpu().data), \n","                end='')\n","    # Eval\n","    evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n","    evaluate_y = Variable(test_loader.dataset.test_labels)\n","    if cuda:\n","        evaluate_x, evaluate_y = evaluate_x.cuda(), evaluate_y.cuda()\n","        \n","        \n","\n","    model.eval()\n","    output = model(evaluate_x)\n","    pred = output.data.max(1)[1]\n","    d = pred.eq(evaluate_y.data).cpu()\n","    accuracy = d.sum()/d.size()[0]\n","    \n","    print('\\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Test Accuracy: {:.4f}%'.format(\n","        epoch+1,\n","        EPOCHS,\n","        len(train_loader.dataset), \n","        len(train_loader.dataset),\n","        100. * batch_idx / len(train_loader), \n","        loss.cpu().data,\n","        accuracy*100,\n","        end=''))\n","plot(losses)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pPGcrrSqdy9","colab_type":"code","colab":{}},"source":["evaluate_x = Variable(test_loader.dataset.test_data.type_as(torch.FloatTensor()))\n","evaluate_y = Variable(test_loader.dataset.test_labels)\n","if cuda:\n","    evaluate_x, evaluate_y = evaluate_x.cuda(), evaluate_y.cuda()\n","\n","model.eval()\n","output = model(evaluate_x)\n","pred = output.data.max(1)[1]\n","d = pred.eq(evaluate_y.data).cpu()\n","accuracy = d.sum()/d.size()[0]\n","print('Accuracy:', accuracy*100)\n","\n"],"execution_count":0,"outputs":[]}]}